<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Seastar</title>
    <link>https://seastar.io/</link>
    <description>Recent content on Seastar</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 Feb 2018 08:02:27 -0800</lastBuildDate><atom:link href="https://seastar.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The Seastar Framework Was Accepted for Google Summer of Code</title>
      <link>https://seastar.io/blog/2018/02/the-seastar-framework-was-accepted-for-google-summer-of-code/</link>
      <pubDate>Wed, 21 Feb 2018 08:02:27 -0800</pubDate>
      
      <guid>https://seastar.io/blog/2018/02/the-seastar-framework-was-accepted-for-google-summer-of-code/</guid>
      <description>By: Raphael Carvalho.
Interested in contributing code to a framework that provides Scylla and other programs with high-throughput I/O and networking? The Scylla team is pleased to announce that the Seastar framework has been accepted as a Google Summer of Code organization. Google Summer of Code with the Seastar project provides students with the opportunity to spend their summer break contributing to an awesome open source project, work under the mentorship of dedicated, brilliant engineers, and in addition receiving a stipend when the project milestones are met.</description>
    </item>
    
    <item>
      <title>Seastar: The future&lt;&gt; is Here</title>
      <link>https://seastar.io/blog/2018/02/seastar-the-future-is-here/</link>
      <pubDate>Tue, 13 Feb 2018 08:02:27 -0800</pubDate>
      
      <guid>https://seastar.io/blog/2018/02/seastar-the-future-is-here/</guid>
      <description>By Alexander Gallego
This is a cross-post from Alexander&amp;rsquo;s Blog.
On June 8, 2016, Avi Kivity came to NYC to present ScyllaDB. During his search for a quick open desk to do some work, I volunteered open spaces we had at Concord1. We talked lock-free algorithms, memory reclamation techniques, threading models, Concord and distributed streaming engines, even C vs C++. Five hours later I was convinced that Seastar was the best systems framework I’d ever come across.</description>
    </item>
    
    <item>
      <title>Frequently Asked Questions</title>
      <link>https://seastar.io/faq/</link>
      <pubDate>Sun, 05 Feb 2017 07:51:49 +0100</pubDate>
      
      <guid>https://seastar.io/faq/</guid>
      <description>What’s the Difference Between the Seastar Model and the Reactive Programming Model? Seastar futures/promises/continuations (f-p-c) are a subset of reactive programming.
Seastar performance derives from the sharded, cooperative, non-blocking, micro-task scheduled design, and f-p-c are a friendlier way of feeding tasks to the scheduler.
Seastar’s f-p-c do have some optimizations relative to other f-p-c designs. They trade off thread safety, which is unneeded due to the sharded design, for scheduling efficiency, and have a very low memory footprint.</description>
    </item>
    
    <item>
      <title>Futures and Promises</title>
      <link>https://seastar.io/futures-promises/</link>
      <pubDate>Sun, 05 Feb 2017 07:51:49 +0100</pubDate>
      
      <guid>https://seastar.io/futures-promises/</guid>
      <description>Paradigms for parallellization Solutions for coordinating work across multiple cores are many. Some are highly programmer-friendly and enable development of software that works exactly if it were running on a single core. For example the classic Unix process model is designed to keep each process in total isolation and relies on kernel code to maintain a separate virtual memory space per process. Unfortunately this increases the overhead at the OS level.</description>
    </item>
    
    <item>
      <title>Home</title>
      <link>https://seastar.io/home/</link>
      <pubDate>Sun, 05 Feb 2017 07:51:49 +0100</pubDate>
      
      <guid>https://seastar.io/home/</guid>
      <description></description>
    </item>
    
    <item>
      <title>HTTP performance</title>
      <link>https://seastar.io/http-performance/</link>
      <pubDate>Sun, 05 Feb 2017 07:51:49 +0100</pubDate>
      
      <guid>https://seastar.io/http-performance/</guid>
      <description>Tests of a new Seastar-based HTTP server show that it is capable of ~7M requests/second on a single node. Details of the benchmark follow.
This benchmark uses two identical Intel® Server System R2000WT servers.
  2x Xeon E5-2695v3: 2.3GHz base, 35M cache, 14 core (28 cores per host, with hyperthreading to 56 cores per host)
  8x 8GB DDR4 Micron memory
  12x 300GB Intel S3500 SSD (in RAID5, 3TB of storage for OS)</description>
    </item>
    
    <item>
      <title>Message Passing</title>
      <link>https://seastar.io/message-passing/</link>
      <pubDate>Sun, 05 Feb 2017 07:51:49 +0100</pubDate>
      
      <guid>https://seastar.io/message-passing/</guid>
      <description>Threaded applications require inherently expensive locking operations, while the Seastar model can completely avoid locks for cross-CPU communications.
From the programmer’s point of view, Seastar uses futures, promises, and continuations (f/p/c). Where conventional event-driven programming using epoll and userspace libraries such as libevent has made it very difficult to write complex applications, f/p/c makes it easier to write complex asynchronous code.
For example, the following interaction between a sender core, C0, and a receiver core, C1, can take place with no locking required.</description>
    </item>
    
    <item>
      <title>Networking</title>
      <link>https://seastar.io/networking/</link>
      <pubDate>Sun, 05 Feb 2017 07:51:49 +0100</pubDate>
      
      <guid>https://seastar.io/networking/</guid>
      <description>Seastar supports four different networking modes on two platforms, all without application code changes. The same application can be built as a dedicated server appliance or unikernel-based VM.
 DPDK networking on Linux: A Seastar application running on Linux host can access a physical network device directly. Seastar applications can use DPDK when running as a guest, via device assignment, or on bare metal. This mode provides low-latency, high-throughput networking. No system calls are required for communicating, and no data copying ever occurs.</description>
    </item>
    
    <item>
      <title>Seastar Applications</title>
      <link>https://seastar.io/seastar-applications/</link>
      <pubDate>Sun, 05 Feb 2017 07:51:49 +0100</pubDate>
      
      <guid>https://seastar.io/seastar-applications/</guid>
      <description>While many applications can benefit from high performance, Seastar is currently focused on high-throughput, low-latency I/O intensive applications.
 Pedis: Redis-compatible data structure store Scylla: NoSQL column-store database, compatible with Apache Cassandra at 10x the throughput Seastar HTTPD: web server Seastar Memcached: a fast server for the Memcache key-value store  </description>
    </item>
    
    <item>
      <title>Shared-nothing Design</title>
      <link>https://seastar.io/shared-nothing/</link>
      <pubDate>Sun, 05 Feb 2017 07:51:49 +0100</pubDate>
      
      <guid>https://seastar.io/shared-nothing/</guid>
      <description>Hardware on which modern workloads must run is remarkably different from the hardware on which current programming paradigms depend, and for which current software infrastructure is designed.
Core Counts Grow, Clock Speeds Stay Constant Performance increases in clock speeds of individual cores have stopped. The increase in number of cores means that performance depends on coordination across multiple cores, no longer on throughput of a single core.
On new hardware, the performance of standard workloads depends more on locking and coordination across cores than on performance of an individual core.</description>
    </item>
    
  </channel>
</rss>
